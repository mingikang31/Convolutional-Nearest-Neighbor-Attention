layer: ConvNNAttention
patch_size: 16
num_layers: 12
num_heads: 3
d_hidden: 192
d_mlp: 768
dropout: 0.1
attention_dropout: 0.1
K: 11
sampling_type: all
num_samples: -1
sample_padding: 0
magnitude_type: cosine
coordinate_encoding: False
dataset: cifar10
data_path: ./Data
batch_size: 32
num_epochs: 80
use_amp: False
clip_grad_norm: 1.0
criterion: CrossEntropy
optimizer: adamw
momentum: 0.9
weight_decay: 0.05
lr: 1e-05
lr_step: 2
lr_gamma: 0.95
scheduler: cosine
device: cuda
seed: 42
output_dir: ./Output/Sep28_K_Test/CIFAR10/ConvNNAttention_All_K11_s42
resize: True
num_classes: 10
img_size: (3, 224, 224)
model: VIT
total_params: 6029962
trainable_params: 6029962
