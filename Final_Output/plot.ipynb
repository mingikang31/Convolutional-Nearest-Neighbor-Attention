{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d81c923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_training_results(file_path):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    epochs = []\n",
    "    times = []\n",
    "    train_losses = []\n",
    "    train_acc_top1 = []\n",
    "    train_acc_top5 = []\n",
    "    test_losses = []\n",
    "    test_acc_top1 = []\n",
    "    test_acc_top5 = []\n",
    "    \n",
    "    # Regular expression to match each epoch line\n",
    "    pattern = r'\\[Epoch (\\d+)\\] Time: ([\\d.]+)s.*?Train.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%.*?Test.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    for match in matches:\n",
    "        epochs.append(int(match[0]))\n",
    "        times.append(float(match[1]))\n",
    "        train_losses.append(float(match[2]))\n",
    "        train_acc_top1.append(float(match[3]))\n",
    "        train_acc_top5.append(float(match[4]))\n",
    "        test_losses.append(float(match[5]))\n",
    "        test_acc_top1.append(float(match[6]))\n",
    "        test_acc_top5.append(float(match[7]))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': epochs,\n",
    "        'time': times,\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy_top1': train_acc_top1,\n",
    "        'train_accuracy_top5': train_acc_top5,\n",
    "        'test_loss': test_losses,\n",
    "        'test_accuracy_top1': test_acc_top1,\n",
    "        'test_accuracy_top5': test_acc_top5\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def n_last_average_stats(df, last_n_epochs=5):\n",
    "    \"\"\"Calculate average stats over the last N epochs\"\"\"\n",
    "    if len(df) < last_n_epochs:\n",
    "        last_n_epochs = len(df)\n",
    "    \n",
    "    return {\n",
    "        \"ave_train_loss\": df['train_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_loss\": df['test_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top1\": df['train_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top5\": df['train_accuracy_top5'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top1\": df['test_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top5\": df['test_accuracy_top5'].tail(last_n_epochs).mean()\n",
    "    }\n",
    "\n",
    "def best_stats(df):\n",
    "    \"\"\"Calculate best accuracy achieved during training\"\"\"\n",
    "    return {\n",
    "        \"best_train_accuracy_top1\": df['train_accuracy_top1'].max(),\n",
    "        \"best_train_accuracy_top5\": df['train_accuracy_top5'].max(),\n",
    "        \"best_test_accuracy_top1\": df['test_accuracy_top1'].max(),\n",
    "        \"best_test_accuracy_top5\": df['test_accuracy_top5'].max()\n",
    "    }\n",
    "\n",
    "def parse_params_gflops(file_dir):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "\n",
    "    train_path = os.path.join(file_dir, \"train_eval_results.txt\")\n",
    "    args_path = os.path.join(file_dir, \"args.txt\")\n",
    "    \n",
    "    # Read the file\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_content = f.readline()\n",
    "\n",
    "    with open(args_path, 'r') as f:\n",
    "        args_content = f.readlines()\n",
    "\n",
    "    total_params = args_content[-2].strip().split(\": \")[1]\n",
    "    trainable_params = args_content[-1].strip().split(\": \")[1]\n",
    "\n",
    "    gflops = re.search(r'GFLOPs: ([\\d.]+)', train_content).group(1)\n",
    "\n",
    "    return {\n",
    "        \"total_params\": int(total_params),\n",
    "        \"trainable_params\": int(trainable_params),\n",
    "        \"gflops\": float(gflops)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a3d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_training_results(file_path):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    epochs = []\n",
    "    times = []\n",
    "    train_losses = []\n",
    "    train_acc_top1 = []\n",
    "    train_acc_top5 = []\n",
    "    test_losses = []\n",
    "    test_acc_top1 = []\n",
    "    test_acc_top5 = []\n",
    "    \n",
    "    # Regular expression to match each epoch line\n",
    "    pattern = r'\\[Epoch (\\d+)\\] Time: ([\\d.]+)s.*?Train.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%.*?Test.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    for match in matches:\n",
    "        epochs.append(int(match[0]))\n",
    "        times.append(float(match[1]))\n",
    "        train_losses.append(float(match[2]))\n",
    "        train_acc_top1.append(float(match[3]))\n",
    "        train_acc_top5.append(float(match[4]))\n",
    "        test_losses.append(float(match[5]))\n",
    "        test_acc_top1.append(float(match[6]))\n",
    "        test_acc_top5.append(float(match[7]))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': epochs,\n",
    "        'time': times,\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy_top1': train_acc_top1,\n",
    "        'train_accuracy_top5': train_acc_top5,\n",
    "        'test_loss': test_losses,\n",
    "        'test_accuracy_top1': test_acc_top1,\n",
    "        'test_accuracy_top5': test_acc_top5\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def n_last_average_stats(df, last_n_epochs=5):\n",
    "    \"\"\"Calculate average stats over the last N epochs\"\"\"\n",
    "    if len(df) < last_n_epochs:\n",
    "        last_n_epochs = len(df)\n",
    "    \n",
    "    return {\n",
    "        \"ave_train_loss\": df['train_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_loss\": df['test_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top1\": df['train_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top5\": df['train_accuracy_top5'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top1\": df['test_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top5\": df['test_accuracy_top5'].tail(last_n_epochs).mean()\n",
    "    }\n",
    "\n",
    "def best_stats(df):\n",
    "    \"\"\"Calculate best accuracy achieved during training\"\"\"\n",
    "    return {\n",
    "        \"best_train_accuracy_top1\": df['train_accuracy_top1'].max(),\n",
    "        \"best_train_accuracy_top5\": df['train_accuracy_top5'].max(),\n",
    "        \"best_test_accuracy_top1\": df['test_accuracy_top1'].max(),\n",
    "        \"best_test_accuracy_top5\": df['test_accuracy_top5'].max()\n",
    "    }\n",
    "\n",
    "def parse_params_gflops(file_dir):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "\n",
    "    train_path = os.path.join(file_dir, \"train_eval_results.txt\")\n",
    "    args_path = os.path.join(file_dir, \"args.txt\")\n",
    "    \n",
    "    # Read the file\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_content = f.readline()\n",
    "\n",
    "    with open(args_path, 'r') as f:\n",
    "        args_content = f.readlines()\n",
    "\n",
    "    total_params = args_content[-2].strip().split(\": \")[1]\n",
    "    trainable_params = args_content[-1].strip().split(\": \")[1]\n",
    "\n",
    "    gflops = re.search(r'GFLOPs: ([\\d.]+)', train_content).group(1)\n",
    "\n",
    "    return {\n",
    "        \"total_params\": int(total_params),\n",
    "        \"trainable_params\": int(trainable_params),\n",
    "        \"gflops\": float(gflops)\n",
    "    }\n",
    "\n",
    "?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a60abab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "def parse_training_results(file_path):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    epochs = []\n",
    "    times = []\n",
    "    train_losses = []\n",
    "    train_acc_top1 = []\n",
    "    train_acc_top5 = []\n",
    "    test_losses = []\n",
    "    test_acc_top1 = []\n",
    "    test_acc_top5 = []\n",
    "    \n",
    "    # Regular expression to match each epoch line\n",
    "    pattern = r'\\[Epoch (\\d+)\\] Time: ([\\d.]+)s.*?Train.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%.*?Test.*?Loss: ([\\d.]+).*?Top1: ([\\d.]+)%.*?Top5: ([\\d.]+)%'\n",
    "    \n",
    "    # Find all matches\n",
    "    matches = re.findall(pattern, content)\n",
    "    \n",
    "    for match in matches:\n",
    "        epochs.append(int(match[0]))\n",
    "        times.append(float(match[1]))\n",
    "        train_losses.append(float(match[2]))\n",
    "        train_acc_top1.append(float(match[3]))\n",
    "        train_acc_top5.append(float(match[4]))\n",
    "        test_losses.append(float(match[5]))\n",
    "        test_acc_top1.append(float(match[6]))\n",
    "        test_acc_top5.append(float(match[7]))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'epoch': epochs,\n",
    "        'time': times,\n",
    "        'train_loss': train_losses,\n",
    "        'train_accuracy_top1': train_acc_top1,\n",
    "        'train_accuracy_top5': train_acc_top5,\n",
    "        'test_loss': test_losses,\n",
    "        'test_accuracy_top1': test_acc_top1,\n",
    "        'test_accuracy_top5': test_acc_top5\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def n_last_average_stats(df, last_n_epochs=5):\n",
    "    \"\"\"Calculate average stats over the last N epochs\"\"\"\n",
    "    if len(df) < last_n_epochs:\n",
    "        last_n_epochs = len(df)\n",
    "    \n",
    "    return {\n",
    "        \"ave_train_loss\": df['train_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_loss\": df['test_loss'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top1\": df['train_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_train_accuracy_top5\": df['train_accuracy_top5'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top1\": df['test_accuracy_top1'].tail(last_n_epochs).mean(),\n",
    "        \"ave_test_accuracy_top5\": df['test_accuracy_top5'].tail(last_n_epochs).mean()\n",
    "    }\n",
    "\n",
    "def best_stats(df):\n",
    "    \"\"\"Calculate best accuracy achieved during training\"\"\"\n",
    "    return {\n",
    "        \"best_train_accuracy_top1\": df['train_accuracy_top1'].max(),\n",
    "        \"best_train_accuracy_top5\": df['train_accuracy_top5'].max(),\n",
    "        \"best_test_accuracy_top1\": df['test_accuracy_top1'].max(),\n",
    "        \"best_test_accuracy_top5\": df['test_accuracy_top5'].max()\n",
    "    }\n",
    "\n",
    "def parse_params_gflops(file_dir):\n",
    "    \"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\n",
    "\n",
    "    train_path = os.path.join(file_dir, \"train_eval_results.txt\")\n",
    "    args_path = os.path.join(file_dir, \"args.txt\")\n",
    "    \n",
    "    # Read the file\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_content = f.readline()\n",
    "\n",
    "    with open(args_path, 'r') as f:\n",
    "        args_content = f.readlines()\n",
    "\n",
    "    total_params = args_content[-2].strip().split(\": \")[1]\n",
    "    trainable_params = args_content[-1].strip().split(\": \")[1]\n",
    "\n",
    "    gflops = re.search(r'GFLOPs: ([\\d.]+)', train_content).group(1)\n",
    "\n",
    "    return {\n",
    "        \"total_params\": int(total_params),\n",
    "        \"trainable_params\": int(trainable_params),\n",
    "        \"gflops\": float(gflops)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680cd876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output\n",
      "Root Directory: /Users/mingikang/Developer\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import os\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(curr_dir, '..', '..'))\n",
    "\n",
    "print(\"Current Directory:\", curr_dir)\n",
    "print(\"Root Directory:\", root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72117df0",
   "metadata": {},
   "source": [
    "## K Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46558839",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnn_dir = f\"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/K_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K1_s42\"\n",
    "\n",
    "kvt_dir = f\"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/K_test/ViT-Tiny-CIFAR10/KvtAttention_K3_s42\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bfa6303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            dataset            layer  K  ave_train_loss  ave_test_loss  \\\n",
      "0  ViT-Tiny-CIFAR10  ConvNNAttention  1        0.484201       0.853181   \n",
      "1  ViT-Tiny-CIFAR10  ConvNNAttention  2        0.057783       1.677184   \n",
      "2  ViT-Tiny-CIFAR10  ConvNNAttention  3        0.039318       1.808193   \n",
      "3  ViT-Tiny-CIFAR10  ConvNNAttention  4        0.037307       1.880055   \n",
      "4  ViT-Tiny-CIFAR10  ConvNNAttention  5        0.032257       1.890058   \n",
      "\n",
      "   ave_train_accuracy_top1  ave_train_accuracy_top5  ave_test_accuracy_top1  \\\n",
      "0                 82.45680                 99.53148                73.44532   \n",
      "1                 97.96586                 99.99880                73.24414   \n",
      "2                 98.61320                 99.99920                73.35154   \n",
      "3                 98.70406                 99.99960                72.72852   \n",
      "4                 98.88218                 99.99880                73.23634   \n",
      "\n",
      "   ave_test_accuracy_top5  best_train_accuracy_top1  best_train_accuracy_top5  \\\n",
      "0                98.26954                   82.5159                   99.5635   \n",
      "1                97.86718                   98.0544                  100.0000   \n",
      "2                97.88476                   98.6966                  100.0000   \n",
      "3                97.89844                   98.7496                  100.0000   \n",
      "4                97.89260                   98.9732                  100.0000   \n",
      "\n",
      "   best_test_accuracy_top1  best_test_accuracy_top5  total_params  \\\n",
      "0                  74.4043                  98.4375       5481610   \n",
      "1                  73.6621                  98.2910       5483914   \n",
      "2                  73.7988                  98.2129       5486218   \n",
      "3                  73.5742                  98.2129       5488522   \n",
      "4                  73.9746                  98.2324       5490826   \n",
      "\n",
      "   trainable_params    gflops  \n",
      "0           5481610  2.329554  \n",
      "1           5483914  2.330008  \n",
      "2           5486218  2.330462  \n",
      "3           5488522  2.330916  \n",
      "4           5490826  2.331369  \n"
     ]
    }
   ],
   "source": [
    "datasets = [\"ViT-Tiny-CIFAR10\", \"ViT-Tiny-CIFAR100\"]\n",
    "Ks = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"16\", \"25\", \"36\"]\n",
    "layer = [\"ConvNNAttention\", \"KvtAttention\"]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for ds in datasets:\n",
    "    for l in layer: \n",
    "        for k in Ks:\n",
    "            if l == \"ConvNNAttention\":\n",
    "                dir_path = f\"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/K_test_correct/{ds}/ConvNNAttention_K{k}_s42\"\n",
    "            else:\n",
    "                dir_path = f\"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/K_test/{ds}/KvtAttention_K{k}_s42\"\n",
    "\n",
    "            # print(dir_path)\n",
    "            \n",
    "            df = parse_training_results(os.path.join(dir_path, \"train_eval_results.txt\"))\n",
    "            avg_stats = n_last_average_stats(df, last_n_epochs=5)\n",
    "            best_stat = best_stats(df)\n",
    "            params_gflops = parse_params_gflops(dir_path)\n",
    "\n",
    "            row = {\n",
    "                \"dataset\": ds,\n",
    "                \"layer\": l,\n",
    "                \"K\": k,\n",
    "                **avg_stats,\n",
    "                **best_stat,\n",
    "                **params_gflops\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "\n",
    "cifar10_attention_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/Baseline_Test**/ViT-Tiny-CIFAR10/Attention_NH1_s42/train_eval_results.txt\"\n",
    "\n",
    "cifar10_attention_df = parse_training_results(cifar10_attention_path)\n",
    "cifar10_attention_avg_stats = n_last_average_stats(cifar10_attention_df, last_n_epochs=5)\n",
    "cifar10_attention_best_stats = best_stats(cifar10_attention_df)\n",
    "cifar10_attention_params_gflops = parse_params_gflops(os.path.dirname(cifar10_attention_path))\n",
    "\n",
    "\n",
    "\n",
    "cifar100_attention_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/Baseline_Test**/ViT-Tiny-CIFAR100/Attention_NH1_s42/train_eval_results.txt\"\n",
    "\n",
    "cifar100_attention_df = parse_training_results(cifar100_attention_path)\n",
    "cifar100_attention_avg_stats = n_last_average_stats(cifar100_attention_df, last_n_epochs=5)\n",
    "cifar100_attention_best_stats = best_stats(cifar100_attention_df)\n",
    "cifar100_attention_params_gflops = parse_params_gflops(os.path.dirname(cifar100_attention_path))\n",
    "\n",
    "row = {\n",
    "    \"dataset\": \"ViT-Tiny-CIFAR10\",\n",
    "    \"layer\": \"Attention\",\n",
    "    \"K\": \"N/A\",\n",
    "    **cifar10_attention_avg_stats,\n",
    "    **cifar10_attention_best_stats,\n",
    "    **cifar10_attention_params_gflops\n",
    "}\n",
    "\n",
    "rows.append(row)\n",
    "\n",
    "row = {\n",
    "    \"dataset\": \"ViT-Tiny-CIFAR100\",\n",
    "    \"layer\": \"Attention\",\n",
    "    \"K\": \"N/A\",\n",
    "    **cifar100_attention_avg_stats,\n",
    "    **cifar100_attention_best_stats,\n",
    "    **cifar100_attention_params_gflops\n",
    "}\n",
    "\n",
    "rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df.to_csv(os.path.join(curr_dir, \"csv\", \"K_test.csv\"), index=False)\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46427211",
   "metadata": {},
   "source": [
    "## N Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e939529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N16_random_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N16_spatial_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N32_random_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N32_spatial_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N48_random_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N48_spatial_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N64_random_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_N64_spatial_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR100/ConvNNAttention_K9_N16_random_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR100/ConvNNAttention_K9_N16_spatial_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR100/ConvNNAttention_K9_N32_random_s42\n",
      "/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR100/ConvNNAttention_K9_N32_spatial_s42\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR100/ConvNNAttention_K9_N32_spatial_s42/train_eval_results.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     10\u001b[39m dir_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/ConvNNAttention_K9_N\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_s42\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(dir_path)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df = \u001b[43mparse_training_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain_eval_results.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m avg_stats = n_last_average_stats(df, last_n_epochs=\u001b[32m5\u001b[39m)\n\u001b[32m     16\u001b[39m best_stat = best_stats(df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mparse_training_results\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Parse training results from text file into a pandas DataFrame\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Read the file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     10\u001b[39m     content = f.read()\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Initialize lists to store data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch/lib/python3.11/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/ViT-Tiny-CIFAR100/ConvNNAttention_K9_N32_spatial_s42/train_eval_results.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets = [\"ViT-Tiny-CIFAR10\", \"ViT-Tiny-CIFAR100\"]\n",
    "Ns = [\"16\", \"32\", \"48\", \"64\", \"80\", \"96\", \"112\", \"128\", \"144\", \"160\", \"176\", \"192\"]\n",
    "type = [\"random\", \"spatial\"]\n",
    "\n",
    "\n",
    "rows = []\n",
    "for ds in datasets:\n",
    "    for n in Ns: \n",
    "        for t in type:\n",
    "            dir_path = f\"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/N_test_correct/{ds}/ConvNNAttention_K9_N{n}_{t}_s42\"\n",
    "\n",
    "            print(dir_path)\n",
    "            \n",
    "            df = parse_training_results(os.path.join(dir_path, \"train_eval_results.txt\"))\n",
    "            avg_stats = n_last_average_stats(df, last_n_epochs=5)\n",
    "            best_stat = best_stats(df)\n",
    "            params_gflops = parse_params_gflops(dir_path)\n",
    "\n",
    "            row = {\n",
    "                \"dataset\": ds,\n",
    "                \"layer\": \"ConvNNAttention\",\n",
    "                \"N\": n,\n",
    "                \"type\": t,\n",
    "                **avg_stats,\n",
    "                **best_stat,\n",
    "                **params_gflops\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "print(rows)\n",
    "\n",
    "\n",
    "\n",
    "dir_path = f\"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/K_test_correct/ViT-Tiny-CIFAR10/ConvNNAttention_K9_s42\"\n",
    "\n",
    "df = parse_training_results(os.path.join(dir_path, \"train_eval_results.txt\"))\n",
    "avg_stats = n_last_average_stats(df, last_n_epochs=5)\n",
    "best_stat = best_stats(df)\n",
    "params_gflops = parse_params_gflops(dir_path)\n",
    "\n",
    "row = {\n",
    "    \"dataset\": \"ViT-Tiny-CIFAR10\",\n",
    "    \"layer\": \"ConvNNAttention\",\n",
    "    \"N\": \"N/A\",\n",
    "    \"type\": \"all\",\n",
    "    **avg_stats,\n",
    "    **best_stat,\n",
    "    **params_gflops\n",
    "}\n",
    "rows.append(row)\n",
    "\n",
    "dir_path = f\"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/K_test_correct/ViT-Tiny-CIFAR100/ConvNNAttention_K9_s42\"\n",
    "\n",
    "df = parse_training_results(os.path.join(dir_path, \"train_eval_results.txt\"))\n",
    "avg_stats = n_last_average_stats(df, last_n_epochs=5)\n",
    "best_stat = best_stats(df)\n",
    "params_gflops = parse_params_gflops(dir_path)\n",
    "\n",
    "row = {\n",
    "    \"dataset\": \"ViT-Tiny-CIFAR100\",\n",
    "    \"layer\": \"ConvNNAttention\",\n",
    "    \"N\": \"N/A\",\n",
    "    \"type\": \"all\",\n",
    "    **avg_stats,\n",
    "    **best_stat,\n",
    "    **params_gflops\n",
    "}\n",
    "rows.append(row)\n",
    "\n",
    "\n",
    "cifar10_attention_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/Baseline_Test**/ViT-Tiny-CIFAR10/Attention_NH1_s42/train_eval_results.txt\"\n",
    "\n",
    "cifar10_attention_df = parse_training_results(cifar10_attention_path)\n",
    "cifar10_attention_avg_stats = n_last_average_stats(cifar10_attention_df, last_n_epochs=5)\n",
    "cifar10_attention_best_stats = best_stats(cifar10_attention_df)\n",
    "cifar10_attention_params_gflops = parse_params_gflops(os.path.dirname(cifar10_attention_path))\n",
    "\n",
    "\n",
    "\n",
    "cifar100_attention_path = \"/Users/mingikang/Developer/Convolutional-Nearest-Neighbor-Attention/Final_Output/Baseline_Test**/ViT-Tiny-CIFAR100/Attention_NH1_s42/train_eval_results.txt\"\n",
    "\n",
    "cifar100_attention_df = parse_training_results(cifar100_attention_path)\n",
    "cifar100_attention_avg_stats = n_last_average_stats(cifar100_attention_df, last_n_epochs=5)\n",
    "cifar100_attention_best_stats = best_stats(cifar100_attention_df)\n",
    "cifar100_attention_params_gflops = parse_params_gflops(os.path.dirname(cifar100_attention_path))\n",
    "\n",
    "row = {\n",
    "    \"dataset\": \"ViT-Tiny-CIFAR10\",\n",
    "    \"layer\": \"Attention\",\n",
    "    \"N\": \"N/A\",\n",
    "    \"type\": \"N/A\",\n",
    "    **cifar10_attention_avg_stats,\n",
    "    **cifar10_attention_best_stats,\n",
    "    **cifar10_attention_params_gflops\n",
    "}\n",
    "\n",
    "rows.append(row)\n",
    "\n",
    "row = {\n",
    "    \"dataset\": \"ViT-Tiny-CIFAR100\",\n",
    "    \"layer\": \"Attention\",\n",
    "    \"N\": \"N/A\",\n",
    "    \"type\": \"N/A\",\n",
    "    **cifar100_attention_avg_stats,\n",
    "    **cifar100_attention_best_stats,\n",
    "    **cifar100_attention_params_gflops\n",
    "}\n",
    "\n",
    "rows.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "results_df.to_csv(os.path.join(curr_dir, \"csv\", \"N_test.csv\"), index=False)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed913fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>layer</th>\n",
       "      <th>N</th>\n",
       "      <th>type</th>\n",
       "      <th>ave_train_loss</th>\n",
       "      <th>ave_test_loss</th>\n",
       "      <th>ave_train_accuracy_top1</th>\n",
       "      <th>ave_train_accuracy_top5</th>\n",
       "      <th>ave_test_accuracy_top1</th>\n",
       "      <th>ave_test_accuracy_top5</th>\n",
       "      <th>best_train_accuracy_top1</th>\n",
       "      <th>best_train_accuracy_top5</th>\n",
       "      <th>best_test_accuracy_top1</th>\n",
       "      <th>best_test_accuracy_top5</th>\n",
       "      <th>total_params</th>\n",
       "      <th>trainable_params</th>\n",
       "      <th>gflops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ViT-Tiny-CIFAR10</td>\n",
       "      <td>ConvNNAttention</td>\n",
       "      <td>N/A</td>\n",
       "      <td>all</td>\n",
       "      <td>0.028123</td>\n",
       "      <td>1.931252</td>\n",
       "      <td>99.02670</td>\n",
       "      <td>99.99960</td>\n",
       "      <td>73.88280</td>\n",
       "      <td>97.98634</td>\n",
       "      <td>99.0804</td>\n",
       "      <td>100.000</td>\n",
       "      <td>74.3945</td>\n",
       "      <td>98.3203</td>\n",
       "      <td>5500042</td>\n",
       "      <td>5500042</td>\n",
       "      <td>2.333185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ViT-Tiny-CIFAR100</td>\n",
       "      <td>ConvNNAttention</td>\n",
       "      <td>N/A</td>\n",
       "      <td>all</td>\n",
       "      <td>0.059221</td>\n",
       "      <td>3.959703</td>\n",
       "      <td>98.06632</td>\n",
       "      <td>99.98088</td>\n",
       "      <td>48.82422</td>\n",
       "      <td>76.52928</td>\n",
       "      <td>98.1481</td>\n",
       "      <td>99.996</td>\n",
       "      <td>49.1699</td>\n",
       "      <td>77.7734</td>\n",
       "      <td>5517412</td>\n",
       "      <td>5517412</td>\n",
       "      <td>2.333220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ViT-Tiny-CIFAR10</td>\n",
       "      <td>Attention</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>1.605003</td>\n",
       "      <td>98.98950</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>77.12110</td>\n",
       "      <td>98.23828</td>\n",
       "      <td>99.0171</td>\n",
       "      <td>100.000</td>\n",
       "      <td>77.6367</td>\n",
       "      <td>98.6816</td>\n",
       "      <td>5479306</td>\n",
       "      <td>5479306</td>\n",
       "      <td>2.507932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ViT-Tiny-CIFAR100</td>\n",
       "      <td>Attention</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.058465</td>\n",
       "      <td>3.818906</td>\n",
       "      <td>98.10738</td>\n",
       "      <td>99.98604</td>\n",
       "      <td>49.69726</td>\n",
       "      <td>76.93358</td>\n",
       "      <td>98.2541</td>\n",
       "      <td>99.990</td>\n",
       "      <td>50.1855</td>\n",
       "      <td>78.2617</td>\n",
       "      <td>5496676</td>\n",
       "      <td>5496676</td>\n",
       "      <td>2.507966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset            layer    N type  ave_train_loss  \\\n",
       "0   ViT-Tiny-CIFAR10  ConvNNAttention  N/A  all        0.028123   \n",
       "1  ViT-Tiny-CIFAR100  ConvNNAttention  N/A  all        0.059221   \n",
       "2   ViT-Tiny-CIFAR10        Attention  N/A  N/A        0.029531   \n",
       "3  ViT-Tiny-CIFAR100        Attention  N/A  N/A        0.058465   \n",
       "\n",
       "   ave_test_loss  ave_train_accuracy_top1  ave_train_accuracy_top5  \\\n",
       "0       1.931252                 99.02670                 99.99960   \n",
       "1       3.959703                 98.06632                 99.98088   \n",
       "2       1.605003                 98.98950                100.00000   \n",
       "3       3.818906                 98.10738                 99.98604   \n",
       "\n",
       "   ave_test_accuracy_top1  ave_test_accuracy_top5  best_train_accuracy_top1  \\\n",
       "0                73.88280                97.98634                   99.0804   \n",
       "1                48.82422                76.52928                   98.1481   \n",
       "2                77.12110                98.23828                   99.0171   \n",
       "3                49.69726                76.93358                   98.2541   \n",
       "\n",
       "   best_train_accuracy_top5  best_test_accuracy_top1  best_test_accuracy_top5  \\\n",
       "0                   100.000                  74.3945                  98.3203   \n",
       "1                    99.996                  49.1699                  77.7734   \n",
       "2                   100.000                  77.6367                  98.6816   \n",
       "3                    99.990                  50.1855                  78.2617   \n",
       "\n",
       "   total_params  trainable_params    gflops  \n",
       "0       5500042           5500042  2.333185  \n",
       "1       5517412           5517412  2.333220  \n",
       "2       5479306           5479306  2.507932  \n",
       "3       5496676           5496676  2.507966  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2c05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
