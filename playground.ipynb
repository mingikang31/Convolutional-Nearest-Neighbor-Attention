{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25adeb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6156b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test both implementations\n",
    "d_hidden = 768\n",
    "num_heads = 8\n",
    "seq_length = 197\n",
    "batch_size = 4\n",
    "\n",
    "# Create input\n",
    "x = torch.randn(batch_size, seq_length, d_hidden)\n",
    "print(\"Input shape:\", x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a564b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadConvNNAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_hidden, \n",
    "                 num_heads, \n",
    "                 attention_dropout,\n",
    "                 K, \n",
    "                 sampling_type, \n",
    "                 num_samples, \n",
    "                 sample_padding, \n",
    "                 magnitude_type, \n",
    "                 seq_length=197, \n",
    "                 coordinate_encoding=False\n",
    "                 ):\n",
    "        \n",
    "        super(MultiHeadConvNNAttention, self).__init__()\n",
    "        assert d_hidden % num_heads == 0, \"d_hidden must be divisible by num_heads\"\n",
    "\n",
    "        # Core Parameters\n",
    "        self.d_hidden = d_hidden\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.d_k = d_hidden // num_heads\n",
    "\n",
    "        # ConvNN Parameters\n",
    "        self.K = K\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        # 3 types of sampling: all, random, spatial\n",
    "        self.sampling_type = sampling_type\n",
    "        self.num_samples = int(num_samples) \n",
    "        self.sample_padding = int(sample_padding) if sampling_type == 'spatial' else 0    \n",
    "\n",
    "        # Similarity Metric \n",
    "        self.magnitude_type = magnitude_type\n",
    "        self.maximum = True if self.magnitude_type == 'cosine' else False\n",
    "\n",
    "        # Coordinate Encoding (optional) \n",
    "        self.coordinate_encoding = coordinate_encoding\n",
    "        self.coordinate_cache = {}\n",
    "        \n",
    "        # Linear projections for query, key, value\n",
    "        self.W_q = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_k = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_v = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_o = nn.Linear(d_hidden, d_hidden)   \n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "\n",
    "        self.in_channels = (d_hidden // num_heads) + 1 if coordinate_encoding else d_hidden // num_heads\n",
    "        self.out_channels = (d_hidden // num_heads) \n",
    "        \n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.K,\n",
    "            stride=self.K,\n",
    "            padding=0,\n",
    "        )\n",
    "\n",
    "        # Utility Variables \n",
    "        self.INF = 1e5 \n",
    "        self.NEG_INF = -1e5\n",
    "        \n",
    "    def split_head(self, x): \n",
    "        batch_size, seq_length, d_hidden = x.size()\n",
    "        self.batch_size = batch_size\n",
    "        # self.seq_length = seq_length\n",
    "        return x.contiguous().view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2) # (B, num_heads, seq_length, d_k)\n",
    "        \n",
    "    def combine_heads(self, x): \n",
    "        \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_hidden) \n",
    "    \n",
    "    def batch_split(self, x): \n",
    "        x = x.reshape(self.batch_size, -1, self.d_k, self.seq_length)\n",
    "        return x.permute(0, 1, 3, 2).contiguous()\n",
    "        \n",
    "    def batch_combine(self, x): \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        x = x.permute(0, 1, 3, 2).contiguous() \n",
    "        return x.view(-1, self.d_k, seq_length)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Note: x shape: (B, seq_length, d_hidden)\n",
    "        print(\"Input shape:\", x.shape)\n",
    "        # 1. Splithead & Batch Combine\n",
    "        k = self.batch_combine(self.split_head(self.W_k(x)))\n",
    "        v = self.batch_combine(self.split_head(self.W_v(x)))\n",
    "\n",
    "        print(\"k shape after split and combine:\", k.shape)\n",
    "\n",
    "        # 3. Add Coordinate Encoding \n",
    "        k = self._add_coordinate_encoding(k) if self.coordinate_encoding else k\n",
    "        v = self._add_coordinate_encoding(v) if self.coordinate_encoding else v\n",
    "\n",
    "        print(\"k shape after encoding:\", k.shape)\n",
    "\n",
    "        \n",
    "        if self.sampling_type == 'all': # All Samples\n",
    "            q = self.batch_combine(self.split_head(self.W_q(x)))\n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "            print(\"q shape: \", q.shape)\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix(k, q, sqrt=True)\n",
    "            print(\"similarity_marix: \", similarity_matrix.shape)\n",
    "            prime = self._prime(v, similarity_matrix, self.K, self.maximum)\n",
    "            print(\"prime: \", prime.shape)\n",
    "\n",
    "        elif self.sampling_type == 'random': # Random Samples\n",
    "            rand_idx = torch.randperm(x.shape[1], device=x.device)[:self.num_samples]\n",
    "            x_sample = x[:, rand_idx, :]\n",
    "            print(\"x sample shape: \", x_sample.shape)\n",
    "            \n",
    "            q = self.batch_combine(self.split_head(self.W_q(x_sample)))\n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "            print(\"q shape: \", q.shape)\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix_N(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix_N(k, q, sqrt=True)\n",
    "\n",
    "            print(\"similarity_marix: \", similarity_matrix.shape)\n",
    "            range_idx = torch.arange(len(rand_idx), device=q.device)\n",
    "            similarity_matrix[:, rand_idx, range_idx] = self.INF if self.magnitude_type == 'euclidean' else self.NEG_INF\n",
    "\n",
    "            prime = self._prime_N(v, similarity_matrix, self.K, rand_idx, self.maximum)\n",
    "\n",
    "            print(\"prime: \", prime.shape)\n",
    "        elif self.sampling_type == 'spatial': # Spatial Samples\n",
    "            spat_idx = torch.linspace(0 + self.sample_padding, x.shape[1] - self.sample_padding - 1, self.num_samples, device=x.device).long()\n",
    "            x_sample = x[:, spat_idx, :]\n",
    "            print(\"x sample shape: \", x_sample.shape)\n",
    "            q = self.batch_combine(self.split_head(self.W_q(x_sample)))\n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "            print(\"q shape: \", q.shape)\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix_N(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix_N(k, q, sqrt=True)\n",
    "\n",
    "            print(\"similarity_marix: \", similarity_matrix.shape)\n",
    "            range_idx = torch.arange(len(spat_idx), device=q.device)\n",
    "            similarity_matrix[:, spat_idx, range_idx] = self.INF if self.magnitude_type == 'euclidean' else self.NEG_INF\n",
    "\n",
    "            prime = self._prime_N(v, similarity_matrix, self.K, spat_idx, self.maximum)\n",
    "\n",
    "            print(\"prime: \", prime.shape)\n",
    "\n",
    "        else: \n",
    "            raise ValueError(\"Invalid sampling_type. Must be one of ['all', 'random', 'spatial']\")\n",
    "\n",
    "        x = self.conv(prime)  \n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = x.permute(0, 2, 1) \n",
    "        x = self.W_o(self.combine_heads(self.batch_split(x)))\n",
    "        return x       \n",
    "\n",
    "    def _calculate_euclidean_matrix(self, K, Q, sqrt=False):\n",
    "        k_norm_squared = torch.sum(K**2, dim=1, keepdim=True)\n",
    "        q_norm_squared = torch.sum(Q**2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(K.transpose(1, 2), Q)\n",
    "\n",
    "        dist_matrix = k_norm_squared.transpose(1, 2) + q_norm_squared - 2 * dot_product\n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0.0)\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix\n",
    "        torch.diagonal(dist_matrix, dim1=1, dim2=2).fill_(-0.1)  # Fill diagonal with -0.1 to avoid self-selection\n",
    "        return dist_matrix \n",
    "\n",
    "    def _calculate_euclidean_matrix_N(self, K, Q, sqrt=False):\n",
    "        k_norm_squared = torch.sum(K**2, dim=1, keepdim=True)\n",
    "        q_norm_squared = torch.sum(Q**2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(K.transpose(1, 2), Q)\n",
    "\n",
    "        dist_matrix = k_norm_squared.transpose(1, 2) + q_norm_squared - 2 * dot_product\n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0.0)\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix\n",
    "        return dist_matrix \n",
    "\n",
    "    def _calculate_cosine_matrix(self, K, Q):\n",
    "        k_norm = F.normalize(K, p=2, dim=1)\n",
    "        q_norm = F.normalize(Q, p=2, dim=1)\n",
    "        similarity_matrix = torch.matmul(k_norm.transpose(1, 2), q_norm)\n",
    "        torch.diagonal(similarity_matrix, dim1=1, dim2=2).fill_(1.1)  # Fill diagonal with 1.1 to self-select\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _calculate_cosine_matrix_N(self, K, Q):\n",
    "        norm_k = F.normalize(K, p=2, dim=1)\n",
    "        norm_q = F.normalize(Q, p=2, dim=1)\n",
    "        similarity_matrix = torch.matmul(norm_k.transpose(1, 2), norm_q)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _prime(self, v, qk, K, maximum):\n",
    "        b, c, t = v.shape\n",
    "        topk_values, topk_indices = torch.topk(qk, k=K, dim=2, largest=maximum)\n",
    "        topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        v_expanded = v.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        prime = torch.gather(v_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = topk_values_exp * prime \n",
    "\n",
    "        prime = prime.view(b, c, -1)\n",
    "\n",
    "        return prime\n",
    "\n",
    "    def _prime_N(self, v, qk, K, rand_idx, maximum):\n",
    "        b, c, t = v.shape\n",
    "        topk_values, topk_indices = torch.topk(qk, k=K-1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "        # Map sample indicies back to original matrix positions \n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "        token_indices = torch.arange(t, device=v.device).view(1, t, 1).expand(b, t, 1)\n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=-1)\n",
    "        topk_indices_exp = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        # Expand topk values to match the shape of indices\n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K-1)\n",
    "        ones = torch.ones((b, c, t, 1), device=v.device)\n",
    "        topk_values_exp = torch.cat((ones, topk_values_exp), dim=-1)\n",
    "\n",
    "        # Gather matrix values and apply similarity weighting \n",
    "        v_expanded = v.unsqueeze(-1).expand(b, c, t, K).contiguous()    \n",
    "        prime = torch.gather(v_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = topk_values_exp * prime\n",
    "\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _add_coordinate_encoding(self, x):\n",
    "        b, c, t = x.shape \n",
    "        cache_key = f\"{b}_{t}_{x.device}\"\n",
    "        if cache_key in self.coordinate_cache: \n",
    "            expanded_coords = self.coordinate_cache[cache_key]\n",
    "        else: \n",
    "            coords_vec = torch.linspace(start=-1, end=1, steps=t, device=x.device).unsqueeze(0).expand(b, -1) \n",
    "            expanded_coords = coords_vec.unsqueeze(1).expand(b, -1, -1) \n",
    "            self.coordinate_cache[cache_key] = expanded_coords\n",
    "\n",
    "        x_with_coords = torch.cat([x, expanded_coords], dim=1) \n",
    "        return x_with_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4e660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 197, 768])\n",
      "k shape after split and combine: torch.Size([32, 96, 197])\n",
      "k shape after encoding: torch.Size([32, 97, 197])\n",
      "q shape:  torch.Size([32, 97, 197])\n",
      "similarity_marix:  torch.Size([32, 197, 197])\n",
      "prime:  torch.Size([32, 97, 788])\n",
      "Output shape: torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "convnn= MultiHeadConvNNAttention(\n",
    "    d_hidden=d_hidden,\n",
    "    num_heads=8,\n",
    "    attention_dropout=0.1,\n",
    "    K=4,\n",
    "    sampling_type='all',  # 'all', 'random', 'spatial'\n",
    "    num_samples=-1, \n",
    "    sample_padding=0, \n",
    "    magnitude_type='euclidean',  # 'euclidean' or 'cosine'\n",
    "    coordinate_encoding=True\n",
    ")\n",
    "ex = convnn(x)\n",
    "print(\"Output shape:\", ex.shape)  # Expected: (B, seq_length, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29581367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 197, 768])\n",
      "k shape after split and combine: torch.Size([32, 96, 197])\n",
      "k shape after encoding: torch.Size([32, 97, 197])\n",
      "x sample shape:  torch.Size([4, 30, 768])\n",
      "q shape:  torch.Size([32, 97, 30])\n",
      "similarity_marix:  torch.Size([32, 197, 30])\n",
      "prime:  torch.Size([32, 97, 788])\n",
      "Output shape: torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "convnn= MultiHeadConvNNAttention(\n",
    "    d_hidden=d_hidden,\n",
    "    num_heads=8,\n",
    "    attention_dropout=0.1,\n",
    "    K=4,\n",
    "    sampling_type='random',  # 'all', 'random', 'spatial'\n",
    "    num_samples=30, \n",
    "    sample_padding=0, \n",
    "    magnitude_type='euclidean',  # 'euclidean' or 'cosine'\n",
    "    coordinate_encoding=True\n",
    ")\n",
    "ex = convnn(x)\n",
    "print(\"Output shape:\", ex.shape)  # Expected: (B, seq_length, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef7f603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 197, 768])\n",
      "k shape after split and combine: torch.Size([32, 96, 197])\n",
      "k shape after encoding: torch.Size([32, 97, 197])\n",
      "x sample shape:  torch.Size([4, 30, 768])\n",
      "q shape:  torch.Size([32, 97, 30])\n",
      "similarity_marix:  torch.Size([32, 197, 30])\n",
      "prime:  torch.Size([32, 97, 788])\n",
      "Output shape: torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "convnn= MultiHeadConvNNAttention(\n",
    "    d_hidden=d_hidden,\n",
    "    num_heads=8,\n",
    "    attention_dropout=0.1,\n",
    "    K=4,\n",
    "    sampling_type='spatial',  # 'all', 'random', 'spatial'\n",
    "    num_samples=30, \n",
    "    sample_padding=0, \n",
    "    magnitude_type='euclidean',  # 'euclidean' or 'cosine'\n",
    "    coordinate_encoding=True\n",
    ")\n",
    "ex = convnn(x)\n",
    "print(\"Output shape:\", ex.shape)  # Expected: (B, seq_length, d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505833d4",
   "metadata": {},
   "source": [
    "## Remove batch split, batch combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aa5607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiHeadConvNNAttention_NoBatchSplit(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_hidden, \n",
    "                 num_heads, \n",
    "                 attention_dropout,\n",
    "                 K, \n",
    "                 sampling_type, \n",
    "                 num_samples, \n",
    "                 sample_padding, \n",
    "                 magnitude_type, \n",
    "                 seq_length=197, \n",
    "                 coordinate_encoding=False\n",
    "                 ):\n",
    "        \n",
    "        super(MultiHeadConvNNAttention_NoBatchSplit, self).__init__()\n",
    "        assert d_hidden % num_heads == 0, \"d_hidden must be divisible by num_heads\"\n",
    "\n",
    "        # Core Parameters\n",
    "        self.d_hidden = d_hidden\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.d_k = d_hidden // num_heads\n",
    "\n",
    "        # ConvNN Parameters\n",
    "        self.K = K\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        # 3 types of sampling: all, random, spatial\n",
    "        self.sampling_type = sampling_type\n",
    "        self.num_samples = int(num_samples) \n",
    "        self.sample_padding = int(sample_padding) if sampling_type == 'spatial' else 0    \n",
    "\n",
    "        # Similarity Metric \n",
    "        self.magnitude_type = magnitude_type\n",
    "        self.maximum = True if self.magnitude_type == 'cosine' else False\n",
    "\n",
    "        # Coordinate Encoding (optional) \n",
    "        self.coordinate_encoding = coordinate_encoding\n",
    "        self.coordinate_cache = {}\n",
    "        \n",
    "        # Linear projections for query, key, value\n",
    "        self.W_q = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_k = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_v = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_o = nn.Linear(d_hidden, d_hidden)   \n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "        # self.in_channels = (d_hidden // num_heads) + 1 if coordinate_encoding else d_hidden // num_heads\n",
    "        # self.out_channels = (d_hidden // num_heads) \n",
    "        self.in_channels = d_hidden + 1 if coordinate_encoding else d_hidden\n",
    "        self.out_channels = d_hidden\n",
    "        \n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.K,\n",
    "            stride=self.K,\n",
    "            padding=0,\n",
    "        )\n",
    "\n",
    "        # Utility Variables \n",
    "        self.INF = 1e5 \n",
    "        self.NEG_INF = -1e5\n",
    "        \n",
    "    def split_head(self, x): \n",
    "        batch_size, seq_length, d_hidden = x.size()\n",
    "        self.batch_size = batch_size\n",
    "        # self.seq_length = seq_length\n",
    "        return x.contiguous().view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2) # (B, num_heads, seq_length, d_k)\n",
    "        \n",
    "    def combine_heads(self, x): \n",
    "        \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_hidden) \n",
    "    \n",
    "    def batch_split(self, x): \n",
    "        x = x.reshape(self.batch_size, -1, self.d_k, self.seq_length)\n",
    "        return x.permute(0, 1, 3, 2).contiguous()\n",
    "        \n",
    "    def batch_combine(self, x): \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        x = x.permute(0, 1, 3, 2).contiguous() \n",
    "        return x.view(-1, self.d_k, seq_length)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Note: x shape: (B, seq_length, d_hidden)\n",
    "\n",
    "        # 1. Splithead & Batch Combine\n",
    "        k = self.W_k(x) \n",
    "        v = self.W_v(x) \n",
    "\n",
    "        print(\"k shape after linear:\", k.shape)\n",
    "        print(\"v shape after linear:\", v.shape)\n",
    "        k = k.transpose(1, 2)   \n",
    "        v = v.transpose(1, 2)\n",
    "        print(\"k shape after transpose:\", k.shape)\n",
    "        print(\"v shape after transpose:\", v.shape)\n",
    "\n",
    "        # k = self.batch_combine(self.split_head(k))\n",
    "        # v = self.batch_combine(self.split_head(v))\n",
    "\n",
    "\n",
    "        # 2. Add Coordinate Encoding \n",
    "        k = self._add_coordinate_encoding(k) if self.coordinate_encoding else k\n",
    "        v = self._add_coordinate_encoding(v) if self.coordinate_encoding else v\n",
    "\n",
    "\n",
    "        # 3. Sampling & Similarity Calculation\n",
    "        if self.sampling_type == 'all': # All Samples\n",
    "            # q = self.batch_combine(self.split_head(self.W_q(x)))\n",
    "            q = self.W_q(x)\n",
    "            q = q.transpose(1, 2)\n",
    "            \n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix(k, q, sqrt=True)\n",
    "            prime = self._prime(v, similarity_matrix, self.K, self.maximum)\n",
    "\n",
    "        elif self.sampling_type == 'random': # Random Samples\n",
    "            rand_idx = torch.randperm(x.shape[1], device=x.device)[:self.num_samples]\n",
    "            x_sample = x[:, rand_idx, :]            \n",
    "            q = self.batch_combine(self.split_head(self.W_q(x_sample)))\n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix_N(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix_N(k, q, sqrt=True)\n",
    "            range_idx = torch.arange(len(rand_idx), device=q.device)\n",
    "            similarity_matrix[:, rand_idx, range_idx] = self.INF if self.magnitude_type == 'euclidean' else self.NEG_INF\n",
    "            prime = self._prime_N(v, similarity_matrix, self.K, rand_idx, self.maximum)\n",
    "\n",
    "        elif self.sampling_type == 'spatial': # Spatial Samples\n",
    "            spat_idx = torch.linspace(0 + self.sample_padding, x.shape[1] - self.sample_padding - 1, self.num_samples, device=x.device).long()\n",
    "            x_sample = x[:, spat_idx, :]\n",
    "            q = self.batch_combine(self.split_head(self.W_q(x_sample)))\n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix_N(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix_N(k, q, sqrt=True)\n",
    "            range_idx = torch.arange(len(spat_idx), device=q.device)\n",
    "            similarity_matrix[:, spat_idx, range_idx] = self.INF if self.magnitude_type == 'euclidean' else self.NEG_INF\n",
    "            prime = self._prime_N(v, similarity_matrix, self.K, spat_idx, self.maximum)\n",
    "            \n",
    "        else: \n",
    "            raise ValueError(\"Invalid sampling_type. Must be one of ['all', 'random', 'spatial']\")\n",
    "\n",
    "        # 4. Conv1d Layer\n",
    "        x = self.conv(prime)  \n",
    "\n",
    "        # 5. Dropout + Reshape (B, seq_length, d_hidden)\n",
    "        x = self.dropout(x)\n",
    "        x = x.permute(0, 2, 1) \n",
    "\n",
    "        # 6. Final Linear Projection\n",
    "        x = self.W_o(x)\n",
    "        return x       \n",
    "\n",
    "    def _calculate_euclidean_matrix(self, K, Q, sqrt=False):\n",
    "        k_norm_squared = torch.sum(K**2, dim=1, keepdim=True)\n",
    "        q_norm_squared = torch.sum(Q**2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(K.transpose(1, 2), Q)\n",
    "\n",
    "        dist_matrix = k_norm_squared.transpose(1, 2) + q_norm_squared - 2 * dot_product\n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0.0)\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix\n",
    "        torch.diagonal(dist_matrix, dim1=1, dim2=2).fill_(-0.1)  # Fill diagonal with -0.1 to avoid self-selection\n",
    "        return dist_matrix \n",
    "\n",
    "    def _calculate_euclidean_matrix_N(self, K, Q, sqrt=False):\n",
    "        k_norm_squared = torch.sum(K**2, dim=1, keepdim=True)\n",
    "        q_norm_squared = torch.sum(Q**2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(K.transpose(1, 2), Q)\n",
    "\n",
    "        dist_matrix = k_norm_squared.transpose(1, 2) + q_norm_squared - 2 * dot_product\n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0.0)\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix\n",
    "        return dist_matrix \n",
    "\n",
    "    def _calculate_cosine_matrix(self, K, Q):\n",
    "        k_norm = F.normalize(K, p=2, dim=1)\n",
    "        q_norm = F.normalize(Q, p=2, dim=1)\n",
    "        similarity_matrix = torch.matmul(k_norm.transpose(1, 2), q_norm)\n",
    "        torch.diagonal(similarity_matrix, dim1=1, dim2=2).fill_(1.1)  # Fill diagonal with 1.1 to self-select\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _calculate_cosine_matrix_N(self, K, Q):\n",
    "        norm_k = F.normalize(K, p=2, dim=1)\n",
    "        norm_q = F.normalize(Q, p=2, dim=1)\n",
    "        similarity_matrix = torch.matmul(norm_k.transpose(1, 2), norm_q)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _prime(self, v, qk, K, maximum):\n",
    "        b, c, t = v.shape\n",
    "        topk_values, topk_indices = torch.topk(qk, k=K, dim=2, largest=maximum)\n",
    "        topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        v_expanded = v.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        prime = torch.gather(v_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = topk_values_exp * prime \n",
    "\n",
    "        prime = prime.view(b, c, -1)\n",
    "\n",
    "        return prime\n",
    "\n",
    "    def _prime_N(self, v, qk, K, rand_idx, maximum):\n",
    "        b, c, t = v.shape\n",
    "        topk_values, topk_indices = torch.topk(qk, k=K-1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "        # Map sample indicies back to original matrix positions \n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "        token_indices = torch.arange(t, device=v.device).view(1, t, 1).expand(b, t, 1)\n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=-1)\n",
    "        topk_indices_exp = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        # Expand topk values to match the shape of indices\n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K-1)\n",
    "        ones = torch.ones((b, c, t, 1), device=v.device)\n",
    "        topk_values_exp = torch.cat((ones, topk_values_exp), dim=-1)\n",
    "\n",
    "        # Gather matrix values and apply similarity weighting \n",
    "        v_expanded = v.unsqueeze(-1).expand(b, c, t, K).contiguous()    \n",
    "        prime = torch.gather(v_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = topk_values_exp * prime\n",
    "\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _add_coordinate_encoding(self, x):\n",
    "        b, c, t = x.shape \n",
    "        cache_key = f\"{b}_{t}_{x.device}\"\n",
    "        if cache_key in self.coordinate_cache: \n",
    "            expanded_coords = self.coordinate_cache[cache_key]\n",
    "        else: \n",
    "            coords_vec = torch.linspace(start=-1, end=1, steps=t, device=x.device).unsqueeze(0).expand(b, -1) \n",
    "            expanded_coords = coords_vec.unsqueeze(1).expand(b, -1, -1) \n",
    "            self.coordinate_cache[cache_key] = expanded_coords\n",
    "\n",
    "        x_with_coords = torch.cat([x, expanded_coords], dim=1) \n",
    "        return x_with_coords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "040d5cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test both implementations\n",
    "d_hidden = 768\n",
    "num_heads = 8\n",
    "seq_length = 197\n",
    "batch_size = 4\n",
    "\n",
    "# Create input\n",
    "x = torch.randn(batch_size, seq_length, d_hidden)\n",
    "print(\"Input shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6117bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k shape after linear: torch.Size([4, 197, 768])\n",
      "v shape after linear: torch.Size([4, 197, 768])\n",
      "k shape after transpose: torch.Size([4, 768, 197])\n",
      "v shape after transpose: torch.Size([4, 768, 197])\n",
      "Output shape: torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "convnn= MultiHeadConvNNAttention_NoBatchSplit(\n",
    "    d_hidden=d_hidden,\n",
    "    num_heads=8,\n",
    "    attention_dropout=0.1,\n",
    "    K=4,\n",
    "    sampling_type='all',  # 'all', 'random', 'spatial'\n",
    "    num_samples=-1, \n",
    "    sample_padding=0, \n",
    "    magnitude_type='euclidean',  # 'euclidean' or 'cosine'\n",
    "    coordinate_encoding=False\n",
    ")\n",
    "ex = convnn(x)\n",
    "print(\"Output shape:\", ex.shape)  # Expected: (B, seq_length, d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b7cfe",
   "metadata": {},
   "source": [
    "## Oct 7, 2025\n",
    "### Figure out a way to add number of heads to the ConvNN Attention layer similar to the MultiHeadAttention layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d62a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2526eb58",
   "metadata": {},
   "source": [
    "#### 1. MultiheadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e62437a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Multi-Head Layers for Transformer Encoder\"\"\"\n",
    "class MultiHeadAttention(nn.Module): \n",
    "    def __init__(self, d_hidden, num_heads, attention_dropout):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_hidden % num_heads == 0, \"d_hidden must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_hidden = d_hidden\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_hidden // num_heads # dimension of each head\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "        \n",
    "        self.W_q = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_k = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_v = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_o = nn.Linear(d_hidden, d_hidden)        \n",
    "    \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        print()\n",
    "        print(\"[Inside scaled_dot_product_attention]\")\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        print(\"attn_scores shape:\", attn_scores.shape)\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn_probs = self.dropout(torch.softmax(attn_scores, dim=-1))\n",
    "        print(\"attn_probs shape:\", attn_probs.shape)\n",
    "        print(\"V shape:\", V.shape)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        print(\"output shape:\", output.shape)\n",
    "        return output, attn_probs\n",
    "    \n",
    "    def split_head(self, x): \n",
    "        batch_size, seq_length, d_hidden = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2) # (B, num_heads, seq_length, d_k)\n",
    "        \n",
    "    def combine_heads(self, x): \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_hidden) \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        print(\"[Inside MultiHeadAttention forward]\")\n",
    "        q = self.split_head(self.W_q(x)) # (B, num_heads, seq_length, d_k)\n",
    "        k = self.split_head(self.W_k(x))\n",
    "        v = self.split_head(self.W_v(x))\n",
    "        print(\"original x shape:\", x.shape)\n",
    "        print(\"kqv shape:\", k.shape, q.shape, v.shape)\n",
    "        \n",
    "        attn_output, _ = self.scaled_dot_product_attention(q, k, v, mask) # (B, num_heads, seq_length, d_k)\n",
    "        output = self.W_o(self.combine_heads(attn_output)) # (B, seq_length, d_hidden)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf2165fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 197, 768])\n",
      "--------------------------------------------------\n",
      "[Inside MultiHeadAttention forward]\n",
      "original x shape: torch.Size([4, 197, 768])\n",
      "kqv shape: torch.Size([4, 3, 197, 256]) torch.Size([4, 3, 197, 256]) torch.Size([4, 3, 197, 256])\n",
      "\n",
      "[Inside scaled_dot_product_attention]\n",
      "attn_scores shape: torch.Size([4, 3, 197, 197])\n",
      "attn_probs shape: torch.Size([4, 3, 197, 197])\n",
      "V shape: torch.Size([4, 3, 197, 256])\n",
      "output shape: torch.Size([4, 3, 197, 256])\n",
      "--------------------------------------------------\n",
      "Output shape: torch.Size([4, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "# Test both implementations\n",
    "d_hidden = 768\n",
    "num_heads = 3\n",
    "seq_length = 197\n",
    "batch_size = 4\n",
    "\n",
    "# Create input\n",
    "x = torch.randn(batch_size, seq_length, d_hidden)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"-\"*50)\n",
    "\n",
    "attention = MultiHeadAttention(d_hidden=d_hidden, num_heads=num_heads, attention_dropout=0.1)\n",
    "out = attention(x)\n",
    "print(\"-\"*50)\n",
    "print(\"Output shape:\", out.shape)  # Expected: (B, seq_length, d_hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d795c",
   "metadata": {},
   "source": [
    "#### 2. ConvNN Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e079b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working implementation \n",
    "class MultiHeadConvNNAttention(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_hidden, \n",
    "                 num_heads, \n",
    "                 attention_dropout,\n",
    "                 K, \n",
    "                 sampling_type, \n",
    "                 num_samples, \n",
    "                 sample_padding, \n",
    "                 magnitude_type, \n",
    "                 seq_length=197, \n",
    "                 coordinate_encoding=False\n",
    "                 ):\n",
    "        \n",
    "        super(MultiHeadConvNNAttention, self).__init__()\n",
    "        assert d_hidden % num_heads == 0, \"d_hidden must be divisible by num_heads\"\n",
    "\n",
    "        # Core Parameters\n",
    "        self.d_hidden = d_hidden\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_dropout = attention_dropout\n",
    "        self.d_k = d_hidden // num_heads\n",
    "\n",
    "        # ConvNN Parameters\n",
    "        self.K = K\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        # 3 types of sampling: all, random, spatial\n",
    "        self.sampling_type = sampling_type\n",
    "        self.num_samples = int(num_samples) \n",
    "        self.sample_padding = int(sample_padding) if sampling_type == 'spatial' else 0    \n",
    "\n",
    "        # Similarity Metric \n",
    "        self.magnitude_type = magnitude_type\n",
    "        self.maximum = True if self.magnitude_type == 'cosine' else False\n",
    "\n",
    "        # Coordinate Encoding (optional) \n",
    "        self.coordinate_encoding = coordinate_encoding\n",
    "        self.coordinate_cache = {}\n",
    "        \n",
    "        # Linear projections for query, key, value\n",
    "        self.W_q = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_k = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_v = nn.Linear(d_hidden, d_hidden)\n",
    "        self.W_o = nn.Linear(d_hidden, d_hidden)   \n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "        self.in_channels = (d_hidden // num_heads) + 1 if coordinate_encoding else (d_hidden // num_heads)\n",
    "        self.out_channels = (d_hidden // num_heads) \n",
    "        \n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.K,\n",
    "            stride=self.K,\n",
    "            padding=0,\n",
    "        )\n",
    "\n",
    "        # Utility Variables \n",
    "        self.INF = 1.1\n",
    "        self.NEG_INF = -0.1 \n",
    "        \n",
    "    def split_head(self, x): \n",
    "        batch_size, seq_length, d_hidden = x.size()\n",
    "        self.batch_size = batch_size\n",
    "        # self.seq_length = seq_length\n",
    "        return x.contiguous().view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2) # (B, num_heads, seq_length, d_k)\n",
    "        \n",
    "    def combine_heads(self, x): \n",
    "        \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_hidden) \n",
    "    \n",
    "    def batch_split(self, x): \n",
    "        x = x.reshape(self.batch_size, -1, self.d_k, self.seq_length)\n",
    "        return x.permute(0, 1, 3, 2).contiguous()\n",
    "        \n",
    "    def batch_combine(self, x): \n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        x = x.permute(0, 1, 3, 2).contiguous() \n",
    "        return x.view(-1, self.d_k, seq_length)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Note: x shape: (B, seq_length, d_hidden)\n",
    "        # 1. Splithead & Batch Combine\n",
    "        k = self.batch_combine(self.split_head(self.W_k(x)))\n",
    "        v = self.batch_combine(self.split_head(self.W_v(x)))\n",
    "        \n",
    "        # k = self.batch_combine(self.split_head(x))\n",
    "        # v = self.batch_combine(self.split_head(x))\n",
    "\n",
    "        # 2. Add Coordinate Encoding \n",
    "        k = self._add_coordinate_encoding(k) if self.coordinate_encoding else k\n",
    "        v = self._add_coordinate_encoding(v) if self.coordinate_encoding else v\n",
    "\n",
    "\n",
    "        # 3. Sampling & Similarity Calculation\n",
    "        if self.sampling_type == 'all': # All Samples\n",
    "            q = self.batch_combine(self.split_head(self.W_q(x)))\n",
    "            # q = self.batch_combine(self.split_head(x))\n",
    "            \n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix(k, q, sqrt=True)\n",
    "\n",
    "            # similarity_matrix = torch.softmax(similarity_matrix, dim=-1)\n",
    "            \n",
    "            prime = self._prime(v, similarity_matrix, self.K, self.maximum)\n",
    "            # prime = self._prime_temperature(v, similarity_matrix, self.K, self.maximum, temperature=1) ## New Prime with Temperature Scaling\n",
    "\n",
    "        elif self.sampling_type == 'random': # Random Samples\n",
    "            rand_idx = torch.randperm(x.shape[1], device=x.device)[:self.num_samples]\n",
    "            x_sample = x[:, rand_idx, :]            \n",
    "            q = self.batch_combine(self.split_head(self.W_q(x_sample)))\n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix_N(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix_N(k, q, sqrt=True)\n",
    "            range_idx = torch.arange(len(rand_idx), device=q.device)\n",
    "            similarity_matrix[:, rand_idx, range_idx] = self.INF if self.magnitude_type == 'euclidean' else self.NEG_INF\n",
    "\n",
    "            # similarity_matrix = torch.softmax(similarity_matrix, dim=-1)\n",
    "\n",
    "            prime = self._prime_N(v, similarity_matrix, self.K, rand_idx, self.maximum)\n",
    "\n",
    "        elif self.sampling_type == 'spatial': # Spatial Samples\n",
    "            spat_idx = torch.linspace(0 + self.sample_padding, x.shape[1] - self.sample_padding - 1, self.num_samples, device=x.device).long()\n",
    "            x_sample = x[:, spat_idx, :]\n",
    "            q = self.batch_combine(self.split_head(self.W_q(x_sample)))\n",
    "            q = self._add_coordinate_encoding(q) if self.coordinate_encoding else q\n",
    "\n",
    "            similarity_matrix = self._calculate_cosine_matrix_N(k, q) if self.magnitude_type == 'cosine' else self._calculate_euclidean_matrix_N(k, q, sqrt=True)\n",
    "            range_idx = torch.arange(len(spat_idx), device=q.device)\n",
    "            similarity_matrix[:, spat_idx, range_idx] = self.INF if self.magnitude_type == 'euclidean' else self.NEG_INF\n",
    "\n",
    "            # similarity_matrix = torch.softmax(similarity_matrix, dim=-1)\n",
    "\n",
    "            prime = self._prime_N(v, similarity_matrix, self.K, spat_idx, self.maximum)\n",
    "            \n",
    "        else: \n",
    "            raise ValueError(\"Invalid sampling_type. Must be one of ['all', 'random', 'spatial']\")\n",
    "\n",
    "        # 4. Conv1d Layer\n",
    "        x = self.conv(prime)  \n",
    "\n",
    "        # 5. Dropout + Reshape (B, seq_length, d_hidden)\n",
    "        x = self.dropout(x)\n",
    "        x = x.permute(0, 2, 1) \n",
    "\n",
    "        # 6. Final Linear Projection\n",
    "        x = self.W_o(self.combine_heads(self.batch_split(x)))\n",
    "        return x       \n",
    "\n",
    "    def _calculate_euclidean_matrix(self, K, Q, sqrt=False):\n",
    "        k_norm_squared = torch.sum(K**2, dim=1, keepdim=True)\n",
    "        q_norm_squared = torch.sum(Q**2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(K.transpose(1, 2), Q)\n",
    "\n",
    "        dist_matrix = k_norm_squared.transpose(1, 2) + q_norm_squared - 2 * dot_product\n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0.0)\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix\n",
    "        torch.diagonal(dist_matrix, dim1=1, dim2=2).fill_(-0.1) \n",
    "        return dist_matrix \n",
    "\n",
    "    def _calculate_euclidean_matrix_N(self, K, Q, sqrt=False):\n",
    "        k_norm_squared = torch.sum(K**2, dim=1, keepdim=True)\n",
    "        q_norm_squared = torch.sum(Q**2, dim=1, keepdim=True)\n",
    "        dot_product = torch.bmm(K.transpose(1, 2), Q)\n",
    "\n",
    "        dist_matrix = k_norm_squared.transpose(1, 2) + q_norm_squared - 2 * dot_product\n",
    "        dist_matrix = torch.clamp(dist_matrix, min=0.0)\n",
    "        dist_matrix = torch.sqrt(dist_matrix) if sqrt else dist_matrix\n",
    "        return dist_matrix \n",
    "\n",
    "    def _calculate_cosine_matrix(self, K, Q):\n",
    "        k_norm = F.normalize(K, p=2, dim=1)\n",
    "        q_norm = F.normalize(Q, p=2, dim=1)\n",
    "        similarity_matrix = torch.matmul(k_norm.transpose(1, 2), q_norm)\n",
    "        torch.diagonal(similarity_matrix, dim1=1, dim2=2).fill_(1.1)  # Fill diagonal with 1.1 to self-select\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _calculate_cosine_matrix_N(self, K, Q):\n",
    "        norm_k = F.normalize(K, p=2, dim=1)\n",
    "        norm_q = F.normalize(Q, p=2, dim=1)\n",
    "        similarity_matrix = torch.matmul(norm_k.transpose(1, 2), norm_q)\n",
    "        similarity_matrix = torch.softmax(similarity_matrix, dim=-1)\n",
    "        return similarity_matrix\n",
    "\n",
    "    def _prime(self, v, qk, K, maximum):\n",
    "        b, c, t = v.shape\n",
    "        topk_values, topk_indices = torch.topk(qk, k=K, dim=2, largest=maximum)\n",
    "        topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        v_expanded = v.unsqueeze(-1).expand(b, c, t, K).contiguous()\n",
    "        prime = torch.gather(v_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = topk_values_exp * prime \n",
    "\n",
    "        prime = prime.view(b, c, -1)\n",
    "\n",
    "        return prime\n",
    "\n",
    "    def _prime_temperature(self, v, qk, K, maximum, temperature=1.0):\n",
    "        b, c, t = v.shape\n",
    "\n",
    "        # Get top-k values and indices\n",
    "        topk_values, topk_indices = torch.topk(qk, k=K, dim=2, largest=maximum)\n",
    "\n",
    "        # Normalize the top-k values to create attention weights\n",
    "        if maximum:  # Cosine similarity\n",
    "            topk_weights = F.softmax(topk_values / temperature, dim=-1)\n",
    "        else:  # Euclidean distance\n",
    "            topk_weights = F.softmax(-topk_values / temperature, dim=-1)\n",
    "\n",
    "        # Expand for gathering\n",
    "        topk_indices_exp = topk_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "        topk_weights_exp = topk_weights.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        # Gather and weight\n",
    "        v_expanded = v.unsqueeze(-1).expand(b, c, t, K)\n",
    "        prime = torch.gather(v_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = prime * topk_weights_exp  # Now using normalized weights\n",
    "\n",
    "        return prime.view(b, c, -1)\n",
    "\n",
    "    def _prime_N(self, v, qk, K, rand_idx, maximum):\n",
    "        b, c, t = v.shape\n",
    "        topk_values, topk_indices = torch.topk(qk, k=K-1, dim=2, largest=maximum)\n",
    "        tk = topk_indices.shape[-1]\n",
    "        assert K == tk + 1, \"Error: K must be same as tk + 1. K == tk + 1.\"\n",
    "\n",
    "        # Map sample indicies back to original matrix positions \n",
    "        mapped_tensor = rand_idx[topk_indices]\n",
    "        token_indices = torch.arange(t, device=v.device).view(1, t, 1).expand(b, t, 1)\n",
    "        final_indices = torch.cat([token_indices, mapped_tensor], dim=-1)\n",
    "        topk_indices_exp = final_indices.unsqueeze(1).expand(b, c, t, K)\n",
    "\n",
    "        # Expand topk values to match the shape of indices\n",
    "        topk_values_exp = topk_values.unsqueeze(1).expand(b, c, t, K-1)\n",
    "        ones = torch.ones((b, c, t, 1), device=v.device)\n",
    "        topk_values_exp = torch.cat((ones, topk_values_exp), dim=-1)\n",
    "\n",
    "        # Gather matrix values and apply similarity weighting \n",
    "        v_expanded = v.unsqueeze(-1).expand(b, c, t, K).contiguous()    \n",
    "        prime = torch.gather(v_expanded, dim=2, index=topk_indices_exp)\n",
    "        prime = topk_values_exp * prime\n",
    "\n",
    "        prime = prime.view(b, c, -1)\n",
    "        return prime\n",
    "    \n",
    "    def _add_coordinate_encoding(self, x):\n",
    "        b, c, t = x.shape \n",
    "        cache_key = f\"{b}_{t}_{x.device}\"\n",
    "        if cache_key in self.coordinate_cache: \n",
    "            expanded_coords = self.coordinate_cache[cache_key]\n",
    "        else: \n",
    "            coords_vec = torch.linspace(start=-1, end=1, steps=t, device=x.device).unsqueeze(0).expand(b, -1) \n",
    "            expanded_coords = coords_vec.unsqueeze(1).expand(b, -1, -1) \n",
    "            self.coordinate_cache[cache_key] = expanded_coords\n",
    "\n",
    "        x_with_coords = torch.cat([x, expanded_coords], dim=1) \n",
    "        return x_with_coords \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
